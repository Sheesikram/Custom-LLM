{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:15.262699Z",
     "iopub.status.busy": "2024-12-06T08:21:15.262373Z",
     "iopub.status.idle": "2024-12-06T08:21:15.587782Z",
     "shell.execute_reply": "2024-12-06T08:21:15.587101Z",
     "shell.execute_reply.started": "2024-12-06T08:21:15.262669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:15.589880Z",
     "iopub.status.busy": "2024-12-06T08:21:15.589411Z",
     "iopub.status.idle": "2024-12-06T08:21:15.901542Z",
     "shell.execute_reply": "2024-12-06T08:21:15.900622Z",
     "shell.execute_reply.started": "2024-12-06T08:21:15.589840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('samsum-train.csv').drop(columns=[\"id\"]).map(str)\n",
    "# df_test = pd.read_csv('samsum-test.csv').drop(columns=[\"id\"]).map(str)\n",
    "# df_validate = pd.read_csv('samsum-validation.csv').drop(columns=[\"id\"]).map(str)\n",
    "# data_test = pd.read_csv('samsum-test.csv').drop(columns=[\"id\"]).map(str)\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv').drop(columns=[\"id\"]).map(str)\n",
    "df_test = pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv').drop(columns=[\"id\"]).map(str)\n",
    "df_validate = pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv').drop(columns=[\"id\"]).map(str)\n",
    "data_test = pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv').drop(columns=[\"id\"]).map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:15.903090Z",
     "iopub.status.busy": "2024-12-06T08:21:15.902747Z",
     "iopub.status.idle": "2024-12-06T08:21:15.907285Z",
     "shell.execute_reply": "2024-12-06T08:21:15.906465Z",
     "shell.execute_reply.started": "2024-12-06T08:21:15.903054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_token = '<|sos|>'\n",
    "end_token = '<|eos|>'\n",
    "pad_token = '<|pad|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:15.910013Z",
     "iopub.status.busy": "2024-12-06T08:21:15.909377Z",
     "iopub.status.idle": "2024-12-06T08:21:15.923214Z",
     "shell.execute_reply": "2024-12-06T08:21:15.922437Z",
     "shell.execute_reply.started": "2024-12-06T08:21:15.909969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['summary'] = df_train['summary'].apply(lambda x: start_token + x + end_token)\n",
    "df_test['summary'] = df_test['summary'].apply(lambda x: start_token + x + end_token)\n",
    "df_validate['summary'] = df_validate['summary'].apply(lambda x: start_token + x + end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:15.924335Z",
     "iopub.status.busy": "2024-12-06T08:21:15.924068Z",
     "iopub.status.idle": "2024-12-06T08:21:20.303353Z",
     "shell.execute_reply": "2024-12-06T08:21:20.302427Z",
     "shell.execute_reply.started": "2024-12-06T08:21:15.924312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:20.305311Z",
     "iopub.status.busy": "2024-12-06T08:21:20.304746Z",
     "iopub.status.idle": "2024-12-06T08:21:24.859751Z",
     "shell.execute_reply": "2024-12-06T08:21:24.859055Z",
     "shell.execute_reply.started": "2024-12-06T08:21:20.305268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674ed13dab27427193030b171dd3725b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820bd1bd2ebf4d00a5bea0af325f0ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02efa77d323f4e949efa677bf2ba2d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25faef0c444d4b188ed3f9b5e6a51c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7844bdb3d9cd4c4182fa6cb3f4d339ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:24.860978Z",
     "iopub.status.busy": "2024-12-06T08:21:24.860749Z",
     "iopub.status.idle": "2024-12-06T08:21:24.871139Z",
     "shell.execute_reply": "2024-12-06T08:21:24.870424Z",
     "shell.execute_reply.started": "2024-12-06T08:21:24.860956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:24.872653Z",
     "iopub.status.busy": "2024-12-06T08:21:24.872324Z",
     "iopub.status.idle": "2024-12-06T08:21:24.885621Z",
     "shell.execute_reply": "2024-12-06T08:21:24.884819Z",
     "shell.execute_reply.started": "2024-12-06T08:21:24.872617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    \"pad_token\": pad_token,\n",
    "    \"additional_special_tokens\": [start_token, end_token]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:24.886760Z",
     "iopub.status.busy": "2024-12-06T08:21:24.886524Z",
     "iopub.status.idle": "2024-12-06T08:21:24.900287Z",
     "shell.execute_reply": "2024-12-06T08:21:24.899514Z",
     "shell.execute_reply.started": "2024-12-06T08:21:24.886737Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50260"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:25.009657Z",
     "iopub.status.busy": "2024-12-06T08:21:25.009006Z",
     "iopub.status.idle": "2024-12-06T08:21:25.013502Z",
     "shell.execute_reply": "2024-12-06T08:21:25.012694Z",
     "shell.execute_reply.started": "2024-12-06T08:21:25.009610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:25.015458Z",
     "iopub.status.busy": "2024-12-06T08:21:25.014751Z",
     "iopub.status.idle": "2024-12-06T08:21:25.023562Z",
     "shell.execute_reply": "2024-12-06T08:21:25.022798Z",
     "shell.execute_reply.started": "2024-12-06T08:21:25.015416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:25.025137Z",
     "iopub.status.busy": "2024-12-06T08:21:25.024830Z",
     "iopub.status.idle": "2024-12-06T08:21:32.205722Z",
     "shell.execute_reply": "2024-12-06T08:21:32.204967Z",
     "shell.execute_reply.started": "2024-12-06T08:21:25.025103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    df_train['dialogue'].tolist(), \n",
    "    max_length=MAX_LENGTH, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "targets = tokenizer(\n",
    "    df_train['summary'].tolist(), \n",
    "    max_length=decoder_length, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:32.207050Z",
     "iopub.status.busy": "2024-12-06T08:21:32.206700Z",
     "iopub.status.idle": "2024-12-06T08:21:32.212868Z",
     "shell.execute_reply": "2024-12-06T08:21:32.211965Z",
     "shell.execute_reply.started": "2024-12-06T08:21:32.207011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14732, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:32.214083Z",
     "iopub.status.busy": "2024-12-06T08:21:32.213794Z",
     "iopub.status.idle": "2024-12-06T08:21:42.946406Z",
     "shell.execute_reply": "2024-12-06T08:21:42.945672Z",
     "shell.execute_reply.started": "2024-12-06T08:21:32.214042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:42.947900Z",
     "iopub.status.busy": "2024-12-06T08:21:42.947444Z",
     "iopub.status.idle": "2024-12-06T08:21:42.997987Z",
     "shell.execute_reply": "2024-12-06T08:21:42.997289Z",
     "shell.execute_reply.started": "2024-12-06T08:21:42.947874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 5840,  5282,    25,  ..., 50257, 50257, 50257],\n",
       "        [   46, 16017,   544,  ..., 50257, 50257, 50257],\n",
       "        [14967,    25, 15902,  ..., 50257, 50257, 50257],\n",
       "        ...,\n",
       "        [ 7554,    25,  3887,  ..., 50257, 50257, 50257],\n",
       "        [43187,    25, 23420,  ..., 50257, 50257, 50257],\n",
       "        [41072,    25,   389,  ..., 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:42.999088Z",
     "iopub.status.busy": "2024-12-06T08:21:42.998873Z",
     "iopub.status.idle": "2024-12-06T08:21:43.006332Z",
     "shell.execute_reply": "2024-12-06T08:21:43.005499Z",
     "shell.execute_reply.started": "2024-12-06T08:21:42.999067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50258,  5840,  5282,  ..., 50257, 50257, 50257],\n",
       "        [50258,    46, 16017,  ..., 50257, 50257, 50257],\n",
       "        [50258, 26374,   743,  ..., 50257, 50257, 50257],\n",
       "        ...,\n",
       "        [50258, 16504,   318,  ..., 50257, 50257, 50257],\n",
       "        [50258,    34, 25418,  ..., 50257, 50257, 50257],\n",
       "        [50258, 41072,   290,  ..., 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.007700Z",
     "iopub.status.busy": "2024-12-06T08:21:43.007478Z",
     "iopub.status.idle": "2024-12-06T08:21:43.012977Z",
     "shell.execute_reply": "2024-12-06T08:21:43.012220Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.007678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.014329Z",
     "iopub.status.busy": "2024-12-06T08:21:43.013990Z",
     "iopub.status.idle": "2024-12-06T08:21:43.023920Z",
     "shell.execute_reply": "2024-12-06T08:21:43.023159Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.014292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs_ids = inputs['input_ids']\n",
    "targets_ids = targets['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.025062Z",
     "iopub.status.busy": "2024-12-06T08:21:43.024830Z",
     "iopub.status.idle": "2024-12-06T08:21:43.650597Z",
     "shell.execute_reply": "2024-12-06T08:21:43.649576Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.025040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs_tensor = tf.cast(inputs_ids, dtype=tf.int32)\n",
    "targets_tensor = tf.cast(targets_ids, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.651855Z",
     "iopub.status.busy": "2024-12-06T08:21:43.651593Z",
     "iopub.status.idle": "2024-12-06T08:21:43.700817Z",
     "shell.execute_reply": "2024-12-06T08:21:43.699974Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.651830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((inputs_tensor, targets_tensor)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.702654Z",
     "iopub.status.busy": "2024-12-06T08:21:43.702013Z",
     "iopub.status.idle": "2024-12-06T08:21:43.759923Z",
     "shell.execute_reply": "2024-12-06T08:21:43.759088Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.702607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.761416Z",
     "iopub.status.busy": "2024-12-06T08:21:43.761142Z",
     "iopub.status.idle": "2024-12-06T08:21:43.770037Z",
     "shell.execute_reply": "2024-12-06T08:21:43.769177Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.761390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, model_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = model_dim // self.num_heads\n",
    "\n",
    "        self.wq = Dense(model_dim)\n",
    "        self.wk = Dense(model_dim)\n",
    "        self.wv = Dense(model_dim)\n",
    "\n",
    "        self.linear_dense = Dense(model_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def compute_scaled_dot_product_attention(self, query, key, value, mask):\n",
    "        dot_product = tf.matmul(query, key, transpose_b=True)\n",
    "        \n",
    "        key_dim = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_dot_product = dot_product / tf.math.sqrt(key_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_dot_product += (mask * -1e9)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(scaled_dot_product, axis=-1)\n",
    "        \n",
    "        output_values = tf.matmul(attention_weights, value)\n",
    "        \n",
    "        return output_values, attention_weights\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        values, attention_weights = self.compute_scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        values = tf.transpose(values, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_values = tf.reshape(values, (batch_size, -1, self.model_dim))\n",
    "\n",
    "        output = self.linear_dense(concat_values)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.771628Z",
     "iopub.status.busy": "2024-12-06T08:21:43.771277Z",
     "iopub.status.idle": "2024-12-06T08:21:43.784570Z",
     "shell.execute_reply": "2024-12-06T08:21:43.783743Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.771591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.785659Z",
     "iopub.status.busy": "2024-12-06T08:21:43.785447Z",
     "iopub.status.idle": "2024-12-06T08:21:43.794866Z",
     "shell.execute_reply": "2024-12-06T08:21:43.794057Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.785637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PointwiseFeedForward(Layer):\n",
    "    def __init__(self, model_dim, hidden, drop_prob=0.1):\n",
    "        super(PointwiseFeedForward, self).__init__()\n",
    "        self.linear1 = Dense(hidden, activation='relu')\n",
    "        self.linear2 = Dense(model_dim)\n",
    "        self.dropout = Dropout(rate=drop_prob)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.796030Z",
     "iopub.status.busy": "2024-12-06T08:21:43.795792Z",
     "iopub.status.idle": "2024-12-06T08:21:43.808580Z",
     "shell.execute_reply": "2024-12-06T08:21:43.807759Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.796006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.809763Z",
     "iopub.status.busy": "2024-12-06T08:21:43.809530Z",
     "iopub.status.idle": "2024-12-06T08:21:43.818965Z",
     "shell.execute_reply": "2024-12-06T08:21:43.818288Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.809740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, model_dim, num_heads, hidden, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(model_dim, num_heads)\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate=rate)\n",
    "\n",
    "        self.ffn = PointwiseFeedForward(model_dim, hidden, drop_prob=rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout2 = Dropout(rate=rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        residual_x = tf.identity(x)\n",
    "        x, _ = self.attention(x, x, x, mask)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.norm1(residual_x + x)\n",
    "        residual_x = tf.identity(x)\n",
    "\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.norm2(residual_x + x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.820179Z",
     "iopub.status.busy": "2024-12-06T08:21:43.819873Z",
     "iopub.status.idle": "2024-12-06T08:21:43.829306Z",
     "shell.execute_reply": "2024-12-06T08:21:43.828506Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.820141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, model_dim, num_heads, hidden, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.attention1 = MultiHeadAttention(model_dim, num_heads)\n",
    "        self.attention2 = MultiHeadAttention(model_dim, num_heads)\n",
    "\n",
    "        self.ffn = PointwiseFeedForward(model_dim, hidden, drop_prob=rate)\n",
    "\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = Dropout(rate=rate)\n",
    "        self.dropout2 = Dropout(rate=rate)\n",
    "        self.dropout3 = Dropout(rate=rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        output1, attention_weights1 = self.attention1(x, x, x, look_ahead_mask)\n",
    "        output1 = self.dropout1(output1, training=training)\n",
    "        output1 = self.norm1(output1 + x)\n",
    "\n",
    "        output2, attention_weights2 = self.attention2(output1, enc_output, enc_output,  padding_mask)\n",
    "        output2 = self.dropout2(output2, training=training)\n",
    "        output2 = self.norm2(output2 + output1)\n",
    "\n",
    "        output3 = self.ffn(output2)\n",
    "        output3 = self.dropout3(output3, training=training)\n",
    "        output3 = self.norm3(output3 + output2)\n",
    "\n",
    "        return output3, attention_weights1, attention_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.835325Z",
     "iopub.status.busy": "2024-12-06T08:21:43.835062Z",
     "iopub.status.idle": "2024-12-06T08:21:43.841296Z",
     "shell.execute_reply": "2024-12-06T08:21:43.840543Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.835282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.842361Z",
     "iopub.status.busy": "2024-12-06T08:21:43.842086Z",
     "iopub.status.idle": "2024-12-06T08:21:43.851939Z",
     "shell.execute_reply": "2024-12-06T08:21:43.851150Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.842336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.853038Z",
     "iopub.status.busy": "2024-12-06T08:21:43.852809Z",
     "iopub.status.idle": "2024-12-06T08:21:43.862120Z",
     "shell.execute_reply": "2024-12-06T08:21:43.861292Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.853016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_positional_encoding(max_position, model_dim):\n",
    "    positions = np.arange(max_position).reshape(-1, 1)\n",
    "    dimensions = np.arange(model_dim).reshape(1, -1)\n",
    "    \n",
    "    angle_exponents = (2 * (dimensions // 2)) / np.float32(model_dim)\n",
    "    angle_rates = 1 / np.power(10000, angle_exponents)\n",
    "    \n",
    "    angle_values = positions * angle_rates\n",
    "    angle_values[:, ::2] = np.sin(angle_values[:, 0::2])\n",
    "    angle_values[:, ::2] = np.cos(angle_values[:, 1::2])\n",
    "    \n",
    "    positional_encoding = np.expand_dims(angle_values, axis=0)\n",
    "    positional_encoding = tf.convert_to_tensor(positional_encoding, dtype=tf.float32)\n",
    "\n",
    "    return positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.863701Z",
     "iopub.status.busy": "2024-12-06T08:21:43.863185Z",
     "iopub.status.idle": "2024-12-06T08:21:43.878594Z",
     "shell.execute_reply": "2024-12-06T08:21:43.877896Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.863673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self,  model_dim, num_layers, num_heads, hidden, input_vocab_size, max_pos_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(input_vocab_size, model_dim)\n",
    "        self.pos_encoding = generate_positional_encoding(max_pos_encoding, self.model_dim)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(model_dim, num_heads, hidden, rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.model_dim, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.879901Z",
     "iopub.status.busy": "2024-12-06T08:21:43.879583Z",
     "iopub.status.idle": "2024-12-06T08:21:43.890053Z",
     "shell.execute_reply": "2024-12-06T08:21:43.889263Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.879863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    def __init__(self, model_dim, num_layers,  num_heads, hidden, target_vocab_size, max_pos_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(target_vocab_size, model_dim)\n",
    "        self.pos_encoding = generate_positional_encoding(max_pos_encoding, model_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(model_dim, num_heads, hidden, rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.model_dim, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.891163Z",
     "iopub.status.busy": "2024-12-06T08:21:43.890936Z",
     "iopub.status.idle": "2024-12-06T08:21:43.905421Z",
     "shell.execute_reply": "2024-12-06T08:21:43.904640Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.891141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.906617Z",
     "iopub.status.busy": "2024-12-06T08:21:43.906372Z",
     "iopub.status.idle": "2024-12-06T08:21:43.918323Z",
     "shell.execute_reply": "2024-12-06T08:21:43.917521Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.906594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(self, model_dim, num_layers, num_heads, hidden, input_vocab_size, target_vocab_size, max_pos_input, max_pos_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(model_dim, num_layers, num_heads, hidden, input_vocab_size, max_pos_input, rate)\n",
    "        self.decoder = Decoder(model_dim, num_layers, num_heads, hidden, target_vocab_size, max_pos_target, rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.919584Z",
     "iopub.status.busy": "2024-12-06T08:21:43.919303Z",
     "iopub.status.idle": "2024-12-06T08:21:43.933716Z",
     "shell.execute_reply": "2024-12-06T08:21:43.932973Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.919559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.934948Z",
     "iopub.status.busy": "2024-12-06T08:21:43.934708Z",
     "iopub.status.idle": "2024-12-06T08:21:43.946110Z",
     "shell.execute_reply": "2024-12-06T08:21:43.945347Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.934920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(LearningRateSchedule): \n",
    "    def __init__(self, model_dim, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.model_dim = tf.cast(self.model_dim, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step* (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.model_dim) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.947342Z",
     "iopub.status.busy": "2024-12-06T08:21:43.947054Z",
     "iopub.status.idle": "2024-12-06T08:21:43.957845Z",
     "shell.execute_reply": "2024-12-06T08:21:43.957050Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.947317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.959447Z",
     "iopub.status.busy": "2024-12-06T08:21:43.958844Z",
     "iopub.status.idle": "2024-12-06T08:21:43.978975Z",
     "shell.execute_reply": "2024-12-06T08:21:43.978279Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.959408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(model_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.980059Z",
     "iopub.status.busy": "2024-12-06T08:21:43.979822Z",
     "iopub.status.idle": "2024-12-06T08:21:43.983932Z",
     "shell.execute_reply": "2024-12-06T08:21:43.983124Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.980036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.985157Z",
     "iopub.status.busy": "2024-12-06T08:21:43.984887Z",
     "iopub.status.idle": "2024-12-06T08:21:43.993767Z",
     "shell.execute_reply": "2024-12-06T08:21:43.993101Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.985132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:43.995071Z",
     "iopub.status.busy": "2024-12-06T08:21:43.994840Z",
     "iopub.status.idle": "2024-12-06T08:21:44.011681Z",
     "shell.execute_reply": "2024-12-06T08:21:44.010818Z",
     "shell.execute_reply.started": "2024-12-06T08:21:43.995049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "# val_loss = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.012912Z",
     "iopub.status.busy": "2024-12-06T08:21:44.012545Z",
     "iopub.status.idle": "2024-12-06T08:21:44.019203Z",
     "shell.execute_reply": "2024-12-06T08:21:44.018490Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.012885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.020868Z",
     "iopub.status.busy": "2024-12-06T08:21:44.020190Z",
     "iopub.status.idle": "2024-12-06T08:21:44.027937Z",
     "shell.execute_reply": "2024-12-06T08:21:44.027223Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.020842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "hidden = 512\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.029128Z",
     "iopub.status.busy": "2024-12-06T08:21:44.028862Z",
     "iopub.status.idle": "2024-12-06T08:21:44.411498Z",
     "shell.execute_reply": "2024-12-06T08:21:44.410518Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.029093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    model_dim,\n",
    "    num_layers,\n",
    "    num_heads,\n",
    "    hidden,\n",
    "    tokenizer.vocab_size,\n",
    "    tokenizer.vocab_size,\n",
    "    max_pos_input=MAX_LENGTH,\n",
    "    max_pos_target=decoder_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.413109Z",
     "iopub.status.busy": "2024-12-06T08:21:44.412850Z",
     "iopub.status.idle": "2024-12-06T08:21:44.419682Z",
     "shell.execute_reply": "2024-12-06T08:21:44.418737Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.413084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    ones = tf.ones((size, size))\n",
    "    req_matrix = tf.linalg.band_part(ones, -1, 0)\n",
    "    toggle_req_matrix = 1 - req_matrix\n",
    "    mask = toggle_req_matrix\n",
    "    return mask\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    padding_mask = tf.math.equal(seq, 0)\n",
    "    padding_mask = tf.cast(padding_mask, tf.float32)\n",
    "    padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
    "    padding_mask = tf.expand_dims(padding_mask, axis=2)\n",
    "    return padding_mask\n",
    "\n",
    "def create_masks(inputs, targets):\n",
    "    enc_padding_mask = create_padding_mask(inputs)\n",
    "    dec_padding_mask = create_padding_mask(inputs)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(targets)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.421045Z",
     "iopub.status.busy": "2024-12-06T08:21:44.420759Z",
     "iopub.status.idle": "2024-12-06T08:21:44.431213Z",
     "shell.execute_reply": "2024-12-06T08:21:44.430424Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.421020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, \n",
    "            tar_inp, \n",
    "            training=True,  \n",
    "            enc_padding_mask=enc_padding_mask, \n",
    "            look_ahead_mask=combined_mask, \n",
    "            dec_padding_mask=dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.432574Z",
     "iopub.status.busy": "2024-12-06T08:21:44.432215Z",
     "iopub.status.idle": "2024-12-06T08:21:44.440959Z",
     "shell.execute_reply": "2024-12-06T08:21:44.440354Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.432540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def validate_step(inp, tar):\n",
    "#     tar_inp = tar[:, :-1]\n",
    "#     tar_real = tar[:, 1:]\n",
    "\n",
    "#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "#     predictions, _ = transformer(\n",
    "#         inp, \n",
    "#         tar_inp, \n",
    "#         training=False,  # Set training to False for validation\n",
    "#         enc_padding_mask=enc_padding_mask, \n",
    "#         look_ahead_mask=combined_mask, \n",
    "#         dec_padding_mask=dec_padding_mask\n",
    "#     )\n",
    "#     loss = loss_function(tar_real, predictions)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T08:21:44.442160Z",
     "iopub.status.busy": "2024-12-06T08:21:44.441914Z",
     "iopub.status.idle": "2024-12-06T08:21:44.455492Z",
     "shell.execute_reply": "2024-12-06T08:21:44.454694Z",
     "shell.execute_reply.started": "2024-12-06T08:21:44.442137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss 4.233\n",
      "Time taken for 1 epoch: 300.13231992721558  secs\n",
      "\n",
      "Epoch 2 Train Loss 2.3458\n",
      "Time taken for 1 epoch: 265.2878189086914 secs\n",
      "\n",
      "Epoch 3 Train Loss 2.1968\n",
      "Time taken for 1 epoch: 267.27801132202148 secs\n",
      "\n",
      "Epoch 4 Train Loss 1.84\n",
      "Time taken for 1 epoch: 263.36598732524287 secs\n",
      "\n",
      "Epoch 5 Train Loss 1.67\n",
      "Time taken for 1 epoch: 265.48732954987592 secs\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_state()\n",
    "    # val_loss.reset_state()\n",
    "\n",
    "    # Training\n",
    "    for (batch, (inp, tar)) in enumerate(ds):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "    # Validation\n",
    "    # for (batch, (inp, tar)) in enumerate(val_ds):\n",
    "    #     val_loss(validate_step(inp, tar))\n",
    "\n",
    "    print('Epoch {} Train Loss {:.4f} '.format(epoch + 1, train_loss.result()))\n",
    "    # print('Epoch {} Train Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1, train_loss.result(), val_loss.result()))\n",
    "    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(dialogue):\n",
    "    input_ids = tokenizer.encode(\n",
    "        dialogue, \n",
    "        return_tensors=\"tf\", \n",
    "        max_length=MAX_LENGTH, \n",
    "        padding='max_length', \n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    encoder_input = input_ids \n",
    "\n",
    "    start_token_id = tokenizer.convert_tokens_to_ids(start_token)\n",
    "    end_token_id = tokenizer.convert_tokens_to_ids(end_token)\n",
    "\n",
    "    output = tf.expand_dims([start_token_id], 0)  \n",
    "\n",
    "    for _ in range(decoder_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, _ = transformer(\n",
    "            encoder_input,\n",
    "            output,\n",
    "            training=False,\n",
    "            enc_padding_mask=enc_padding_mask,\n",
    "            look_ahead_mask=combined_mask,\n",
    "            dec_padding_mask=dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[:, -1:, :]  \n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1, output_type=tf.int32)  \n",
    "\n",
    "        if predicted_id[0][0].numpy() == end_token_id:\n",
    "            break\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)  \n",
    "\n",
    "    generated_ids = output.numpy()[0][1:]  \n",
    "    return generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def summarize(dialogue):\n",
    "    generated_ids = evaluate(dialogue)\n",
    "    summary = tokenizer.decode(\n",
    "        generated_ids, \n",
    "        skip_special_tokens=True, \n",
    "        clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    return summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Text:\n",
      "Nick: You look absolutely gorgeous and have a lovely smile. \n",
      "Nick: Would love to get to know you a bit more. How about we meet up for a drink sometime?\n",
      "Jane: Hmmm... You're shooting a bit above your range aren't you?\n",
      "Nick: Why would you think that hon?\n",
      "Jane: Because I'm not that desperate.\n",
      "Nick: That was a bit below the belt.\n",
      "Nick: You're nice but you're not THAT hot.\n",
      "Jane: Oh is your poor little dick shriveling at the thought?\n",
      "Nick: Actually I'll take it back. Forget about the drink.\n",
      "Nick: Forget I ever wrote to you.\n",
      "Jane: Bye loser!\n",
      "Nick: Fucking bitch!\n",
      "Jane: You're welcome!\n",
      "\n",
      "Predicted Summary:\n",
      "sam is angry with a video that he doesn't want to watch a video video with him\n",
      "\n",
      "Reference Summary: Nick finds Jane pretty and invites her for a drink to get to know her better. Jane rejects Nick and is unpleasant to him. Nick suggests Jane to forget about their conversation.\n",
      "\n",
      "Sample Text:\n",
      "Adam: My friend told me he saw Tim with a guy.\n",
      "Nate: And?\n",
      "Adam: <file_photo>\n",
      "Nate: omg\n",
      "Julia: Yeah, what a shocker\n",
      "Adam: ??? You knew?!\n",
      "Julia: I thought everyone knew\n",
      "Nate: I had no idea\n",
      "Nate: Did he tell you anything?\n",
      "Julia: That he’s gay? God no\n",
      "Adam: Why didn’t you tell us?\n",
      "Julia: First: I assumed you knew\n",
      "Julia: Second: Why would I? it’s not my business\n",
      "Nate: I think he should’ve told us ;/ not cool\n",
      "Adam: yeah, I made a completely idiot out of myself defending him\n",
      "Julia: Against whom? I’m not surprised he didn’t tell you\n",
      "Nate: Well, it’s not fair, we’re his friends\n",
      "Julia: And? Does it change anything?\n",
      "\n",
      "Predicted Summary:\n",
      "adam is angry with a girl that he was drunk\n",
      "\n",
      "Reference Summary: Julia knew Tim was gay, while Adam and Nate didn't. \n",
      "\n",
      "Sample Text:\n",
      "Lilly: sorry, I'm gonna be late\n",
      "Lilly: don't wait for me and order the food\n",
      "Gabriel: no problem, shall we also order something for you?\n",
      "Gabriel: so that you get it as soon as you get to us?\n",
      "Lilly: good idea!\n",
      "Lilly: pasta with salmon and basil is always very tasty there\n",
      "\n",
      "Predicted Summary:\n",
      "mia and jo are going to buy some soup for the soup\n",
      "\n",
      "Reference Summary: Lilly will be late. Gabriel will order pasta with salmon and basil for her.\n",
      "\n",
      "Sample Text:\n",
      "Cara: hey\n",
      "Cara: are you at home\n",
      "Celine: hey Cara\n",
      "Celine: No i'm not\n",
      "Cara: okay then, i just wanted to pass by\n",
      "Celine: im sorry, i can drop by in the evening if you dont mind\n",
      "Cara: its fine, call me then if you decide to come\n",
      "Celine: ok\n",
      "\n",
      "Predicted Summary:\n",
      "fran is at the gym at her place\n",
      "\n",
      "Reference Summary: Celine is not at home, but she will call Cara before visiting her.\n",
      "\n",
      "Sample Text:\n",
      "Craig: Man, u there?\n",
      "Derek: Yeah, tell me\n",
      "Craig: I need help with my computer\n",
      "Derek: What happened?\n",
      "Craig: I don't know exactly but it's not working\n",
      "Derek: Well, ok... give me 20 minutes, got to get to my car\n",
      "Craig: Ok, thanks\n",
      "Derek: No prob\n",
      "\n",
      "Predicted Summary:\n",
      "sam needs to help with his phone\n",
      "\n",
      "Reference Summary: Derek will be at Craig's in 20 minutes to help him with his malfunctioning computer.\n",
      "\n",
      "Sample Text:\n",
      "Emma: Hi neighbour :)\n",
      "Emma: Do you want to take a stroll with the little ones?\n",
      "Abigail: Hey Emma :) I don't think that's a good idea.\n",
      "Abigail: My smog alert app is showing that the norms have been exceeded by 30% today :O\n",
      "Emma: Oh my, that sounds serious.\n",
      "Emma: I need to install that app.\n",
      "\n",
      "Predicted Summary:\n",
      "emily has a dog she will send her the dog\n",
      "\n",
      "Reference Summary: Abigail is not going to take a stroll with the little ones. Her smog alert app is showing that the norms have been exceeded by 30% today.\n",
      "\n",
      "Sample Text:\n",
      "Paul: What color flowers should I get\n",
      "Cindy: any just not yellow\n",
      "Paul: ok, pink?\n",
      "Cindy: no maybe red\n",
      "Paul: just tell me what color and what type ok?\n",
      "Cindy: ugh, red roses! \n",
      "\n",
      "Predicted Summary:\n",
      "lisa is buying some bread\n",
      "\n",
      "Reference Summary: Paul will buy red roses following Cindy's advice.\n",
      "\n",
      "Sample Text:\n",
      "Mary: Hello, I think you've left your credit card at our shop\n",
      "Jenny: Thank you for getting in touch! Thank you so much!\n",
      "Mary: No worries :)\n",
      "Jenny: When can I pick it up?\n",
      "Mary: Whenever you come, it's safe with one of our cashiers :)\n",
      "\n",
      "Predicted Summary:\n",
      "anna will pick up her jacket at the shopping mall at her place\n",
      "\n",
      "Reference Summary: Jenny has left her credit car at the Mary's shop.\n",
      "\n",
      "Sample Text:\n",
      "Gary: Hey, don't forget about Tom's bday party!\n",
      "Lara: I won't! What time should I show up?\n",
      "Gary: Around 5 pm. He's supposed to be back home at 5:30, so we'll have just enough time to prep things up.\n",
      "Lara: You're such a great boyfriend. He will be so happy!\n",
      "Gary: Yep, I am :)\n",
      "Lara: So I'll just pick up the cake and get the balloons...\n",
      "Gary: Thanks, you're so helpful. I've already paid for the cake.\n",
      "Lara: No problem, see you at 5 pm!\n",
      "Gary: See you!\n",
      "\n",
      "Predicted Summary:\n",
      "adam is at work at home at home at 8 pm and will pick up the red wine at the party at 8 pm\n",
      "\n",
      "Reference Summary: It's Tom's birthday. Lara and Gary will come to Tom's place about 5 pm to prepare everything before Tom gets back home at 5:30. Gary has already paid for the cake - Lara will pick it up and she will also get the balloons. \n",
      "\n",
      "Sample Text:\n",
      "Laura: Where are you?\n",
      "Paul: Almost there.\n",
      "Laura: Which is?\n",
      "Paul: Close to the Mac.\n",
      "Laura: That's so far away!\n",
      "Paul: 15 mins\n",
      "Laura: I am not waiting any more, see you some other time.\n",
      "Paul: Please, wait!\n",
      "Laura: I've waited 30 minutes, 15 minutes ago you wrote you were almost here. This is too much.\n",
      "Paul: I am so sorry.\n",
      "Laura: I am not. \n",
      "\n",
      "Predicted Summary:\n",
      "paul is waiting for paul at the door jam paul is waiting for him and is waiting for him\n",
      "\n",
      "Reference Summary: Paul is late for a meeting with Laura and she refuses to wait any longer.\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 60):\n",
    "    dialogue = df_test.dialogue.iloc[i]\n",
    "    print(\"\\nSample Text:\")\n",
    "    print(dialogue)\n",
    "\n",
    "    print(\"\\nPredicted Summary:\")\n",
    "    print(summarize(dialogue))\n",
    "\n",
    "    print(\"\\nReference Summary:\")\n",
    "    print(data_test.summary.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.2452\n",
      "ROUGE-2: 0.0456\n",
      "ROUGE-L: 0.1118\n"
     ]
    }
   ],
   "source": [
    "def evaluate_summaries(data, num_samples=100):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        dialogue = data['dialogue'].iloc[i]\n",
    "        reference_summary = data['summary'].iloc[i]\n",
    "        generated_summary = summarize(dialogue)\n",
    "\n",
    "        scores = scorer.score(reference_summary, generated_summary)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    print(\"ROUGE-1: {:.4f}\".format(result['rouge1'].mid.fmeasure))\n",
    "    print(\"ROUGE-2: {:.4f}\".format(result['rouge2'].mid.fmeasure))\n",
    "    print(\"ROUGE-L: {:.4f}\".format(result['rougeL'].mid.fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_summaries(df_test, num_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3438844,
     "sourceId": 6004344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
